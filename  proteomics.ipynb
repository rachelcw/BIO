{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyensembl\n",
    "import numpy as np\n",
    "from types import MappingProxyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"~/projects/BIO/novel_junction.20230512.tsv\",sep=\"\\t\",index=False)\n",
    "data=pd.read_csv(\"~/projects/BIO/proteomics_MU_junction_all.20230711.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['intron', 'chr', 'start', 'end', 'genes', 'cluster', 'p.adjust',\n",
       "       'strand', 'gene_id', 'known', 'transcript_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to get the genes by individual.\n",
    "def get_gene_list(genelist):\n",
    "    data_gene_list=[]\n",
    "    for value in genelist:\n",
    "        value = value.split(',')\n",
    "        data_gene_list.extend(value)\n",
    "        \n",
    "    return list(set(data_gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /private1/private/resources/Homo_sapiens_assembly19.fasta.pickle\n"
     ]
    }
   ],
   "source": [
    "genome = pyensembl.Genome(\n",
    "    reference_name='GRCh37',\n",
    "    annotation_name='my_genome_lab',\n",
    "    gtf_path_or_url='/home/ls/rachelcw/projects/protein_coding.gtf',\n",
    "    transcript_fasta_paths_or_urls= '/private1/private/resources/Homo_sapiens_assembly19.fasta')\n",
    "genome.index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************\n",
    "prepare data table- merge leafcutter ds results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutated VS unmutated SF3B1 - group 2 - M+U CLL\n",
    "\n",
    "# read in the data\n",
    "cluster = pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a2.20230512_cluster_significance.txt',sep=\" \")\n",
    "effect_size=pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a2.20230512_effect_sizes.txt',sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold of 10% for deltaPSI\n",
    "effect_size=effect_size[np.abs(effect_size[\"deltapsi\"])>0.1]\n",
    "# filtered out junction mut(psi) > unmut(psi) --> delta psi < 0\n",
    "mutated=effect_size[effect_size[\"deltapsi\"]<0]\n",
    "# unmutated=effect_size[effect_size[\"deltapsi\"]>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mutated[[\"chr\",\"start\",\"end\",\"cluster\"]]=mutated[\"intron\"].str.split(\":\",expand=True)\n",
    "mutated[\"start\"]=mutated[\"start\"].astype(int)\n",
    "mutated[\"end\"]=mutated[\"end\"].astype(int)\n",
    "print(mutated[\"cluster\"].unique().shape)\n",
    "cluster[[\"chr\",\"cluster\"]]=cluster[\"cluster\"].str.split(\":\",expand=True)\n",
    "mutated=mutated.merge(cluster,on=[\"chr\",\"cluster\"],how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=mutated.filter(items=[\"intron\",\"chr\",\"start\",\"end\",\"genes\",\"cluster\",\"p.adjust\"])\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "all_intron=pd.read_csv(\"/data01/private/resources/leafcutter_annot/leafcutter_annot_all_introns.bed.gz\",sep=\"\\t\",header=None,compression=\"gzip\",usecols=[0,1,2,3,4,5,6,8],names=[\"chr\",\"start\",\"end\",\"gene\",\"gene_id\",\"strand\",\"transcript_id\",\"annotation\"])\n",
    "protein_intron=all_intron[all_intron[\"annotation\"]==\"protein_coding\"]\n",
    "data_gene_list=get_gene_list(data['genes'].unique())\n",
    "intron_in_data=protein_intron[protein_intron[\"gene\"].isin(data_gene_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"cluster\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtf=pd.read_csv(\"/private/resources/gencode19_noChrPrefix_mitoMT.gtf\",sep=\"\\t\", comment='#', header=None)\n",
    "# all_intron=pd.read_csv(\"/home/ls/rachelcw/projects/BIO/annontation_code.20221225_all_introns.bed.gz\",sep=\"\\t\",header=None,compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['cluster','strand']]=data['cluster'].str.rsplit('_', expand=True, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows based on comma-separated values\n",
    "new_rows = []\n",
    "for index, row in data.iterrows():\n",
    "    values = row['genes'].split(',')\n",
    "    if len(values) > 1:\n",
    "        for i, value in enumerate(values):\n",
    "            new_row = row.copy()\n",
    "            new_row['genes'] = value\n",
    "            new_rows.append(new_row)\n",
    "    else:\n",
    "        new_rows.append(row)\n",
    "\n",
    "# Create updated DataFrame\n",
    "data = pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict={key: value for key, value in zip(protein_intron[\"gene\"],protein_intron[\"gene_id\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18696"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_intron[\"gene\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"gene_id\"]=data[\"genes\"].map(gene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intron      0\n",
       "chr         0\n",
       "start       0\n",
       "end         0\n",
       "genes       0\n",
       "cluster     0\n",
       "p.adjust    0\n",
       "strand      0\n",
       "gene_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop gene that arn't \"protein coding\" \n",
    "data.dropna(axis=0,inplace=True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"known\"]=pd.NA\n",
    "data[\"transcript_id\"]=pd.NA\n",
    "for gene in data_gene_list:\n",
    "    # data_gene=data[data[\"genes\"].str.contains(gene)]\n",
    "    # intron_gene=intron_in_data[intron_in_data[\"gene\"].str.contains(gene)]\n",
    "    for index,row in data.iterrows():\n",
    "        if ((intron_in_data[\"start\"]==row[\"start\"]).any()&(intron_in_data[\"end\"]==row[\"end\"]).any()):\n",
    "            data.loc[index,\"known\"]=\"known\"\n",
    "            start_trans_id = intron_in_data.loc[intron_in_data['start'] == row[\"start\"], 'transcript_id']\n",
    "            end_trans_id = intron_in_data.loc[intron_in_data['end'] == row[\"end\"], 'transcript_id']\n",
    "            trans_id = pd.concat([start_trans_id, end_trans_id], ignore_index=True)\n",
    "            # trans_id=intron_in_data.loc[(intron_in_data['start'] == row[\"start\"]) & (intron_in_data['transcript_id'].isin(intron_in_data.loc[intron_in_data['end'] == row[\"end\"], 'transcript_id'])), 'transcript_id']\n",
    "            data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "        elif (intron_in_data[\"start\"]==row[\"start\"]).any():\n",
    "            data.loc[index,\"known\"]=\"start\"\n",
    "            trans_id=intron_in_data.loc[intron_in_data[\"start\"]==row[\"start\"],\"transcript_id\"]\n",
    "            data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "        elif (intron_in_data[\"end\"]==row[\"end\"]).any():\n",
    "            data.loc[index,\"known\"]=\"end\"\n",
    "            trans_id=intron_in_data.loc[intron_in_data[\"end\"]==row[\"end\"],\"transcript_id\"]\n",
    "            data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "        else:\n",
    "            data.loc[index,\"known\"]=\"novel\"\n",
    "            transcript_of_intron=genome.transcript_ids_at_locus(contig=row.chr.replace(\"chr\",\"\"),position=row.end) \n",
    "            mask = protein_intron['transcript_id'].isin(transcript_of_intron)\n",
    "            # Get the transcript IDs that are present\n",
    "            present_transcript_ids = protein_intron.loc[mask, 'transcript_id'].tolist()\n",
    "            if len(present_transcript_ids)>0:\n",
    "                data.loc[index,\"transcript_id\"]=','.join(present_transcript_ids)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"gene_id\"].isin(intron_in_data[\"gene_id\"].unique()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intron           0\n",
       "chr              0\n",
       "start            0\n",
       "end              0\n",
       "genes            0\n",
       "cluster          0\n",
       "p.adjust         0\n",
       "strand           0\n",
       "gene_id          0\n",
       "known            0\n",
       "transcript_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()\n",
    "# data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"~/projects/BIO/proteomics_MU_junction_all.20230711.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-90042f41d77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# cassette exons #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mknown_intron\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"known\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"known\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstart_end_intron\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintron_in_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mknown_intron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstart_end_intron\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mse_intron\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknown_intron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknown_intron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# cassette exons #\n",
    "known_intron=data[data[\"known\"]==\"known\"]\n",
    "start_end_intron=[tuple(x) for x in intron_in_data[[\"start\",\"end\"]].values]\n",
    "se=[tuple(x) for x in known_intron[[\"start\",\"end\"]].values if tuple(x) not in start_end_intron]\n",
    "se_intron=known_intron.loc[known_intron[[\"start\",\"end\"]].apply(tuple,1).isin(se)]\n",
    "        \n",
    "unknown_intron=data[data[\"known\"]!=\"known\"]\n",
    "novel_intron= pd.concat([unknown_intron,se_intron], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_intron.to_csv(\"~/projects/BIO/novel_intron.20230710.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENST00000374719.3', 'ENST00000396050.1', 'ENST00000451436.2']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "intron_in_data.loc[(intron_in_data['start'] ==65817935) & (intron_in_data['transcript_id'].isin(intron_in_data.loc[intron_in_data['end'] == 65819881, 'transcript_id'])), 'transcript_id']\n",
    "genome.transcript_ids_at_locus(contig=\"X\",position=65819881,end=65817935,strand=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(novel_intron[\"cluster\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_list=get_gene_list(novel_intron[\"transcript_id\"])\n",
    "\n",
    "len(transcript_list)\n",
    "# len(novel_intron[\"intron\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dictionary: key-transcript id, values- exons-cds location of the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter_not_cds:  0\n",
      "counter_dup:  37\n"
     ]
    }
   ],
   "source": [
    "transcript_strand_cds=dict()\n",
    "\n",
    "counter_not_cds=0\n",
    "counter_dup=0\n",
    "\n",
    "for index, row in novel_intron.iterrows():\n",
    "    transcript=row[\"transcript_id\"].split(\",\")\n",
    "    chr=row[\"intron\"].split(\":\")[0].replace(\"chr\",\"\")\n",
    "    for t in transcript:\n",
    "        if t not in transcript_strand_cds:\n",
    "            try:\n",
    "                cds=genome.transcript_by_id(t).coding_sequence_position_ranges\n",
    "                transcript_strand_cds[t]=[chr,row[\"strand\"],cds]\n",
    "            except:\n",
    "                counter_not_cds+=1\n",
    "                continue\n",
    "        else:\n",
    "            counter_dup+=1\n",
    "           \n",
    "print(\"counter_not_cds: \",counter_not_cds)\n",
    "transcript_strand_cds=MappingProxyType(transcript_strand_cds)\n",
    "print(\"counter_dup: \",counter_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript_exons=dict()\n",
    "# for index, row in novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     for t in transcript:\n",
    "#         if t not in transcript_exons:\n",
    "#             exons=genome.exon_ids_of_transcript_id(t)\n",
    "#             locus=[genome.locus_of_exon_id(exon).to_tuple() for exon in exons]\n",
    "#             transcript_exons[t]=locus            \n",
    "            \n",
    "# # create the dictionary constant\n",
    "# transcript_exons=MappingProxyType(transcript_exons)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* known **start intron** = end exon1.\n",
    "we want to find out the start of exon2, the closest exon to the end of the intron(start of the next exon) and replace the exon start with the novel intron end\n",
    "\n",
    "* known **end intron** = start exon2.  \n",
    "we want to find out the end of exon1,the closest exon to the start of the intron(end of the previous exon) and replace the exon end with the novel intron start\n",
    "\n",
    "* known **novel intron**.\n",
    "the intron is novel so we want to find the closest exons that the intron is between- the novel start exon2 and the novel end exon1\n",
    "\n",
    "* known **known**.\n",
    "it is casset exon so we want to remove the exon between the start and the end of the intron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_novel_gene_locus_forward(transcript, start, end, known):\n",
    "    locus=transcript_strand_cds[transcript][2].copy()\n",
    "    start_cds=transcript_strand_cds[transcript][2][0][0]\n",
    "    end_cds=transcript_strand_cds[transcript][2][-1][1]\n",
    "    if known==\"start\":\n",
    "        # known start of the intron -> novel start exon is the end of the intron\n",
    "        if end<start_cds or start>end_cds:\n",
    "            return None #the event is in utr\n",
    "        start_exon=np.array([l[0] for l in locus])\n",
    "        index_exon=np.argmax(start_exon>end)\n",
    "        if start==locus[index_exon][1] & end != locus[index_exon][0]:\n",
    "            index_exon=index_exon+1 # the index refers to the same exon as the known start -> take the next exon\n",
    "        new_exon_locus=tuple([end,locus[index_exon][1]])\n",
    "        locus[index_exon]=new_exon_locus\n",
    "    elif known==\"end\":\n",
    "        # known end of the intron -> novel end exon is the start of the intron\n",
    "        if end<start_cds or start>end_cds:\n",
    "            return None #the event is in utr\n",
    "        end_exon=np.array([l[1] for l in locus])\n",
    "        index_exon=np.argmin(end_exon<start)\n",
    "        if end==locus[index_exon][0] & start != locus[index_exon][1]:\n",
    "            index_exon=index_exon-1 # the index refers to the same exon as the known end -> take the previous exon \n",
    "        new_exon_locus=tuple([locus[index_exon][0],start])\n",
    "        locus[index_exon]=new_exon_locus\n",
    "    elif known==\"novel\":\n",
    "        if end<start_cds or start>end_cds:\n",
    "            return None\n",
    "        index_start=-1\n",
    "        index_end=-1\n",
    "        if end>start_cds and end<end_cds:\n",
    "            # novel start of exon\n",
    "            start_exon=np.array([l[0] for l in locus])\n",
    "            index_start=np.argmax(start_exon>end)\n",
    "            if start==locus[index_start][1] & end != locus[index_exon][0]:\n",
    "                index_start=index_start+1\n",
    "        if start<end_cds and start>start_cds:\n",
    "            # novel end of exon\n",
    "            end_exon=np.array([l[1] for l in locus])\n",
    "            index_end=np.argmin(end_exon<start)\n",
    "            if end==locus[index_end][0] & start != locus[index_end][1]:\n",
    "                index_end=index_end-1\n",
    "        if index_start==-1 and index_end==-1:\n",
    "            return None #the event is in 5' utr\n",
    "        if index_start!=-1:\n",
    "            # novel start exon is the end of the intron\n",
    "            new_start=tuple([end,locus[index_start][1]])\n",
    "            locus[index_start]=new_start\n",
    "        if index_end!=-1:\n",
    "            # novel end exon is the start of the intron\n",
    "            new_end=tuple([locus[index_end][0],start])\n",
    "            locus[index_end]=new_end \n",
    "    elif known==\"known\":\n",
    "        if end<start_cds or start>end_cds:\n",
    "            return None #the event is in utr\n",
    "        if start<start_cds and end>end_cds:\n",
    "            return \"skip cds\" #the event skip on the cds region\n",
    "        if start<start_cds and end>start_cds:\n",
    "            #skip on the start of the cds exon\n",
    "            index=[i for i, tuple in enumerate(locus) if tuple[0]==end]\n",
    "            index_remove=[i for i in range(len(locus)) if index[0]<i]\n",
    "            locus=[locus[i] for i in range(len(locus)) if i not in index_remove]\n",
    "            return locus\n",
    "        print(\"intron:\",start,end)\n",
    "        index_start=[i for i, tuple in enumerate(locus) if start in tuple] # the first exon\n",
    "        index_end=[i for i, tuple in enumerate(locus) if end in tuple] # the second exon\n",
    "        print(index_start,index_end)\n",
    "        index_remove=[i for i in range(len(locus)) if index_start[0]<i<index_end[0]]\n",
    "        locus=[locus[i] for i in range(len(locus)) if i not in index_remove]\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_novel_gene_locus_reverse(transcript, start, end, known):\n",
    "    # important: in translation the start_cds=end_cds and the end_cds=start_cds  #\n",
    "        locus=transcript_strand_cds[transcript][2].copy()\n",
    "        start_cds=transcript_strand_cds[transcript][2][0][1]\n",
    "        end_cds=transcript_strand_cds[transcript][2][-1][0]\n",
    "        if known == \"start\":\n",
    "            if end<end_cds or start>start_cds:\n",
    "                return None\n",
    "            start_exon=np.array([l[0] for l in locus])\n",
    "            index_exon=np.argmin(start_exon>end)\n",
    "            if start==locus[index_exon][1]:\n",
    "                index_exon=index_exon-1\n",
    "            new_exon_locus=tuple([end,locus[index_exon][1]])\n",
    "            locus[index_exon]=new_exon_locus\n",
    "        elif known == \"end\":\n",
    "            if end<end_cds or start>start_cds:\n",
    "                return None\n",
    "            end_exon=np.array([l[1] for l in locus])\n",
    "            index_exon=np.argmax(end_exon<start)\n",
    "            if end==locus[index_exon][0]:\n",
    "                index_exon=index_exon+1\n",
    "            new_exon_locus=tuple([locus[index_exon][0],start])\n",
    "            locus[index_exon]=new_exon_locus\n",
    "        elif known == \"novel\":\n",
    "            if end<end_cds or start>start_cds:\n",
    "                return None\n",
    "            index_start=-1\n",
    "            index_end=-1\n",
    "            if end<start_cds and end>end_cds:\n",
    "                # novel start of exon\n",
    "                start_exon=np.array([l[0] for l in locus])\n",
    "                index_start=np.argmin(start_exon>end)\n",
    "                if start==locus[index_start][1] & end != locus[index_exon][0]:\n",
    "                    index_start=index_start-1\n",
    "            if start>end_cds and start<start_cds:\n",
    "                # novel end of exon\n",
    "                end_exon=np.array([l[1] for l in locus])\n",
    "                index_end=np.argmax(end_exon<start)\n",
    "                if end==locus[index_end][0] & start != locus[index_end][1]:\n",
    "                    index_end=index_end+1\n",
    "            if index_start==-1 and index_end==-1:\n",
    "                return None  #the event is in utr\n",
    "            if index_start!=-1:\n",
    "                # novel start exon is the end of the intron\n",
    "                new_start=tuple([end,locus[index_start][1]])\n",
    "                locus[index_start]=new_start\n",
    "            if index_end!=-1:\n",
    "                # novel end exon is the start of the intron\n",
    "                new_end=tuple([locus[index_end][0],start])\n",
    "                locus[index_end]=new_end\n",
    "        elif known == \"known\":\n",
    "            if end<end_cds or start>start_cds :\n",
    "                return None #the event is in utr \n",
    "            if start<end_cds and end>start_cds:\n",
    "                return \"skip cds\" #the event skip on the cds region\n",
    "            if start<end_cds and start_cds>end>end_cds:\n",
    "                # the start is out of the cds region and the end is in the cds region\n",
    "                index=[i for i, tuple in enumerate(locus) if tuple[1]==start] #TODO: check if it is the right index\n",
    "                index_remove=[i for i in range(len(locus)) if index[0]<i]\n",
    "                locus=[locus[i] for i in range(len(locus)) if i not in index_remove]\n",
    "                return locus\n",
    "            index_start=[i for i, tuple in enumerate(locus) if start in tuple]\n",
    "            index_end=[i for i, tuple in enumerate(locus) if end in tuple]\n",
    "            index_remove=[i for i in range(len(locus)) if index_end[0]<i<index_start[0]]\n",
    "            locus=[locus[i] for i in range(len(locus)) if i not in index_remove]\n",
    "        return locus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'novel_intron' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d16e031c00f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtranscript_gene_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnovel_intron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtranscript\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcript_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtranscript_gene_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gene_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'novel_intron' is not defined"
     ]
    }
   ],
   "source": [
    "transcript_gene_id=dict()\n",
    "for index, row in novel_intron.iterrows():\n",
    "    transcript=row[\"transcript_id\"].split(\",\")\n",
    "    for t in transcript:\n",
    "        transcript_gene_id[t]=row[\"gene_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcript_strand_cds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# file known exons(cds) #\n",
    "file_path=\"/data01/private/projects/splicing_cll/results/proteomics/mutated_cll_sf3b1_proteomics_reference.txt\"\n",
    "rows=0 # num of transcripts\n",
    "with open(file_path,'w') as file:\n",
    "    for t,value in transcript_strand_cds.items():\n",
    "        chr=value[0]\n",
    "        strand=value[1]\n",
    "        cds=value[2]\n",
    "        rows+=1\n",
    "        for loci in cds:\n",
    "            file.write(f'{chr}\\t{loci[0]}\\t{loci[1]}\\t{strand}\\t{t}\\t{transcript_gene_id[t]}\\n')\n",
    "        \n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript_strand_cds[\"ENST00000557630.1\"][2]\n",
    "# start 24025552 end 24027904\n",
    "# pd.merge(intron_in_data[intron_in_data['start'] == 24025552], intron_in_data[intron_in_data[\"end\"]==24027904], on='transcript_id', how='inner')[\"transcript_id\"].unique()\n",
    "\n",
    "# intron_in_data.loc[(intron_in_data[\"start\"]==24025552)&(intron_in_data[\"end\"]==24027904),\"transcript_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_start_read(start_cds,locus,strand):\n",
    "    if strand==\"+\":\n",
    "        start_locus=locus[0][0]\n",
    "        if start_locus==start_cds:\n",
    "            return 5 # start read from 5'\n",
    "        else:\n",
    "            return 0 # start read from atg\n",
    "    else: # strand==\"-\"\n",
    "        start_locus=locus[0][1]\n",
    "        if start_locus==start_cds:\n",
    "            return 5 # start read from 5'\n",
    "        else:\n",
    "            return 0 # start read from atg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "0\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# file novel exons(cds) #\n",
    "novel_intron=reverse\n",
    "file_path=\"/data01/private/projects/splicing_cll/results/proteomics/mutated_cll_sf3b1_proteomics_novel.txt\"\n",
    "rows=0 # num of transcripts\n",
    "t_not_cds=0 # num of transcripts not in cds\n",
    "events=0\n",
    "novel_in_utr=open(\"/data01/private/projects/splicing_cll/results/proteomics/mutated_cll_sf3b1_proteomics_novel_in_utr.txt\",'w')\n",
    "with open(file_path,'w') as file:\n",
    "    for index, row in novel_intron.iterrows():\n",
    "        transcript=row[\"transcript_id\"].split(\",\")\n",
    "        events+=(len(transcript))\n",
    "        for t in transcript:\n",
    "            if t not in transcript_strand_cds.keys():\n",
    "                t_not_cds+=1\n",
    "                continue\n",
    "            locus=[]\n",
    "            strand=transcript_strand_cds[t][1]\n",
    "            chr=transcript_strand_cds[t][0]\n",
    "            start_cds=-1\n",
    "            end_cds=-1\n",
    "            if strand==\"-\":\n",
    "                start_cds=transcript_strand_cds[t][2][0][1]\n",
    "                end_cds=transcript_strand_cds[t][2][-1][0]\n",
    "                locus=get_novel_gene_locus_reverse(t,row[\"start\"],row[\"end\"],row[\"known\"])\n",
    "            else: # strand==\"+\"\n",
    "                start_cds=transcript_strand_cds[t][2][0][0]\n",
    "                end_cds=transcript_strand_cds[t][2][-1][1]\n",
    "                locus=get_novel_gene_locus_forward(t,row[\"start\"],row[\"end\"],row[\"known\"])\n",
    "            if locus is None:\n",
    "                novel_in_utr.write(f'>{row[\"gene_id\"]}|{t}|{row[\"intron\"]}|\\n')\n",
    "                continue\n",
    "            if locus==\"skip cds\":\n",
    "                print(f'{t} skip cds')\n",
    "                continue\n",
    "            start_from=check_start_read(start_cds,locus,strand)\n",
    "            rows+=1                                      \n",
    "            for loci in locus:\n",
    "                file.write(f'{chr}\\t{loci[0]}\\t{loci[1]}\\t{strand}\\t{t}\\t{transcript_gene_id[t]}\\t{row[\"intron\"]}\\t{start_from}\\n')\n",
    "                # print(f'{chr}\\t{loci[0]}\\t{loci[1]}\\t{strand}\\t{t}\\t{transcript_gene_id[t]}\\t{row[\"intron\"]}\\n') #\n",
    "novel_in_utr.close()\n",
    "print(rows)\n",
    "print(t_not_cds)\n",
    "print(events)\n",
    "# t==\"ENST00000376510.3\" --> +\n",
    "# t==\"ENST00000378927.3\" --> -\n",
    "# t==\"ENST00000331272.7\" --> casset exon\n",
    "# # 103371526 *103384502*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24025967, 24026334)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_strand_cds[\"ENST00000557630.1\"][2]\n",
    "# ENST00000404535.3 ,\n",
    "# cds: 24025967 24026334\n",
    "# junction: 24025552 24027904\n",
    "# locus: (24025967, 24026513), (24027904, 24028046)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmd=all_intron[all_intron[\"annotation\"]==\"nonsense_mediated_decay\"]\n",
    "\n",
    "X=nmd.merge(protein_intron,how=\"inner\",on=\"transcript_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "introns=pd.read_csv(\"/data01/private/resources/leafcutter_annot/leafcutter_annot_all_introns.bed.gz\",sep=\"\\t\",header=None,compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(289920, 290075),\n",
       " (290390, 290600),\n",
       " (290678, 290781),\n",
       " (291002, 291113),\n",
       " (291976, 292000)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_strand_cds[\"ENST00000482937.2\"][2]\n",
    "# genome.exons_at_locus(\"14\",end=24025552)\n",
    "# start 24025552 end 24027904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Specify the path to your FASTA file\n",
    "known_protein = \"/home/ls/rachelcw/projects/BIO/mutated/mutated_cll_sf3b1_proteomics_known_protein.txt\"\n",
    "novel_protein = \"/home/ls/rachelcw/projects/BIO/mutated/mutated_cll_sf3b1_proteomics_novel_protein.txt\"\n",
    "\n",
    "# Read the sequences from the FASTA file\n",
    "known_sequences = []\n",
    "for record in SeqIO.parse(known_protein, \"fasta\"):\n",
    "    sequence_id = record.id\n",
    "    sequence = record.seq\n",
    "    known_sequences.append((sequence_id, sequence))\n",
    "\n",
    "novel_sequences = []\n",
    "for record in SeqIO.parse(novel_protein, \"fasta\"):\n",
    "    sequence_id = record.id\n",
    "    sequence = record.seq\n",
    "    novel_sequences.append((sequence_id, sequence))\n",
    "\n",
    "# print(known_sequences[0][0])\n",
    "# print(novel_sequences[0][0])\n",
    "# print(f\"Found {len(sequences)} sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.pairwise2 import align\n",
    "\n",
    "def calculate_identity(seq1, seq2):\n",
    "    alignments = align.globalxx(seq1, seq2)\n",
    "    # print(alignments)\n",
    "    top_alignment = alignments[0]\n",
    "    alignment_length = top_alignment[4]\n",
    "    matches = top_alignment[2]\n",
    "    identity = (matches / alignment_length) * 100\n",
    "    return np.round(identity,3)\n",
    "\n",
    "# Example protein sequences\n",
    "results=pd.DataFrame(columns=[\"known_id\",\"novel_id\",\"known_seq\",\"novel_seq\",\"identity\"])\n",
    "\n",
    "for known in known_sequences:\n",
    "    for novel in novel_sequences:\n",
    "        if novel[0].startswith(known[0]):\n",
    "            identity = calculate_identity(known[1], novel[1])\n",
    "            # if identity==100:\n",
    "            #     print(\"known\",known[0])\n",
    "            #     print(\"novel\",novel[0])\n",
    "            results=results.append({\"known_id\":known[0],\"novel_id\":novel[0],\"known_seq\":str(known[1]),\"novel_seq\":str(novel[1]),\"identity\":identity},ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# results.to_csv(\"/home/ls/rachelcw/projects/BIO/proteomics/cll_sf3b1_proteomics_table.csv\",index=False)\n",
    "# Convert sequences to arrays of characters\n",
    "# seq1_array = np.array(list(seq1))\n",
    "# seq2_array = np.array(list(seq2))\n",
    "\n",
    "# # Calculate the identity percentage\n",
    "# identity_percentage = calculate_identity(seq1_array, seq2_array)\n",
    "# print(f\"Identity percentage: {identity_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(results[results[\"identity\"]==100])/len(results)\n",
    "identity=results[results[\"identity\"]==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "identity[\"junction\"]=identity[\"novel_id\"].str.rsplit(\"|\",2,expand=True)[1]\n",
    "identity[\"transcript_id\"]=identity[\"novel_id\"].str.split(\"|\",2,expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ls/rachelcw/projects/BIO/proteomics/100_cases.txt\",'w') as file:\n",
    "    for index, row in identity.iterrows():\n",
    "        file.write(row[\"transcript_id\"]+'\\n')\n",
    "        file.write(row[\"junction\"]+'\\n')\n",
    "        file.write(f'{transcript_strand_cds[row[\"transcript_id\"]][2][-1]}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGTTTCACGACACGCTGCACGTGAGCGGCGTGTACAATGGGGCTGGCGGGGACACGCACCGGGCCATGCTGCCCAGCCCCCTCAACGTCCGGCTGGAGGCCCCTGCAGGGATGGGGGAGCAGCTGACCGAGACCTTCGCCCTGGACACCAACACAG\n"
     ]
    }
   ],
   "source": [
    "import pyfaidx as fa\n",
    "fasta =fa.Fasta(\"/private1/private/resources/Homo_sapiens_assembly19.fasta\")\n",
    "s=fasta[\"11\"][289920-1:290075].seq\n",
    "# s1=fasta[\"11\"][290919:291113].seq\n",
    "print(s)\n",
    "# print(s1)\n",
    "# print(len(s))\n",
    "# print(s1[0:100])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(72437665, 72438173),\n",
       " (72425197, 72425366),\n",
       " (72424221, 72424288),\n",
       " (72423483, 72423613),\n",
       " (72423241, 72423384),\n",
       " (72422475, 72422544),\n",
       " (72422066, 72422186),\n",
       " (72421430, 72421632),\n",
       " (72420915, 72421021),\n",
       " (72418220, 72418419),\n",
       " (72416850, 72416935),\n",
       " (72415197, 72415379),\n",
       " (72413950, 72414124),\n",
       " (72412694, 72412828),\n",
       " (72410462, 72410597),\n",
       " (72410050, 72410152),\n",
       " (72408956, 72409151),\n",
       " (72408643, 72408694),\n",
       " (72408368, 72408531),\n",
       " (72408028, 72408240),\n",
       " (72407594, 72407699),\n",
       " (72406763, 72406910),\n",
       " (72406587, 72406673),\n",
       " (72406432, 72406500),\n",
       " (72406025, 72406142),\n",
       " (72404737, 72404850),\n",
       " (72404370, 72404515),\n",
       " (72403798, 72403830),\n",
       " (72399500, 72399582),\n",
       " (72398733, 72398783),\n",
       " (72398484, 72398547),\n",
       " (72397087, 72397236),\n",
       " (72396712, 72396726)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# genome.exon_ids_of_transcript_id(\"ENST00000368644.1\")\n",
    "# genome.coding_sequence(\"ENST00000368644.1\")\n",
    "\n",
    "genome.transcript_by_id(\"ENST00000393609.3\").coding_sequence_position_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=genome.transcript_sequence(transcript_id='ENST00000393605.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c4ee89e0ee24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"intron1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ENST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"intron1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ENST1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ENSG2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"intron1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ENST1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ENSG2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"intron2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ENST2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ENSG2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "transcript=collections.namedtuple(\"transcript\",['chr', 'start', 'end','strand','gene_id'])\n",
    "transcript=transcript(11,1,2,'-','ENSG')\n",
    "d={\"intron1\":[{\"ENST\":transcript}]}\n",
    "d[\"intron1\"].append({\"ENST1\":[transcript._make([11,1,2,'-','ENSG2'])]})\n",
    "d[\"intron1\"][\"ENST1\"].append(transcript._make([12,1,2,'-','ENSG2']))\n",
    "d[\"intron2\"]={\"ENST2\":transcript._make([11,1,2,'-','ENSG2'])}\n",
    "print(d)\n",
    "for i in d.keys():\n",
    "    print(i)\n",
    "    for j in d[i].keys():\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option to frame shift- need to change the modulo to the len of the gene until the new locus # #\n",
    "# start_novel_intron=novel_intron[novel_intron[\"novel\"]==\"start\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in start_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     t_frame=[]\n",
    "#     for t in transcript:\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         print(row[\"end\"])\n",
    "#         print(start_exon)\n",
    "#         index_exon=np.abs(start_exon-row[\"end\"]).argmin()\n",
    "#         print(index_exon)\n",
    "#         print(\"old\",transcript_exons[t][index_exon])\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],row[\"end\"],transcript_exons[t][index_exon][2],transcript_exons[t][index_exon][3]])\n",
    "#         transcript_exons_updated[t][index_exon]=new_exon_locus\n",
    "#         if (transcript_exons[t][index_exon][2]-transcript_exons[t][index_exon][1]-1)%3!=0:\n",
    "#             print(\"new\",new_exon_locus)\n",
    "#             t_frame.append(t)\n",
    "#     start_novel_intron.loc[index,\"frameshift\"]=','.join(t_frame)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my tryint to create a dictionary of {intron(junction):{t_is:[exons locus]}} ##\n",
    "\n",
    "# intron_transcript=dict()\n",
    "# for index, row in novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     intron_transcript[row[\"intron\"]] = [{t: transcript_exons[t]} for t in transcript]\n",
    "\n",
    "# start_novel_intron=novel_intron[novel_intron[\"novel\"]==\"start\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in start_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         index_exon=np.argmax(start_exon>row[\"end\"])\n",
    "#         if row[\"start\"]==transcript_exons[t][index_exon][2]:\n",
    "#             index_exon=index_exon+1\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],row[\"end\"],transcript_exons[t][index_exon][2],transcript_exons[t][index_exon][3]])\n",
    "#         # print(intron_transcript[row[\"intron\"]][i][t][index_exon])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_exon]=new_exon_locus\n",
    "#         # print(intron_transcript[row[\"intron\"]][i][t][index_exon])\n",
    "#         # print(t)\n",
    "#         # print(row[\"end\"])\n",
    "#         # print(start_exon)\n",
    "#         # print(index_exon)\n",
    "#         # print(\"old\",transcript_exons[t][index_exon])\n",
    "#         # print(transcript_exons[t])\n",
    "#         # print(\"new\",new_exon_locus)\n",
    "           \n",
    "# end_novel_intron=novel_intron[novel_intron[\"novel\"]==\"end\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in end_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     # t_frame=[]\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         end_exon=np.array([l[2] for l in transcript_exons[t]])\n",
    "#         index_exon=np.argmin(end_exon<row[\"start\"])\n",
    "#         if row[\"end\"]==transcript_exons[t][index_exon][1]:\n",
    "#             index_exon=index_exon-1\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],transcript_exons[t][index_exon][1],row[\"start\"],transcript_exons[t][index_exon][3]])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_exon]=new_exon_locus\n",
    "#         # print(end_exon<row[\"start\"])\n",
    "#         # print(t)\n",
    "#         # print(row[\"start\"])\n",
    "#         # print(end_exon)\n",
    "#         # print(index_exon)\n",
    "#         # print(\"old\",transcript_exons[t][index_exon])\n",
    "#         # print(transcript_exons[t])\n",
    "#         # print(\"new\",new_exon_locus)\n",
    "\n",
    "# novel_novel_intron=novel_intron[novel_intron[\"novel\"]==\"novel\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in novel_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     # t_frame=[]\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         end_exon=np.array([l[2] for l in transcript_exons[t]])\n",
    "#         index_start=np.argmax(start_exon>row[\"end\"])\n",
    "#         if row[\"start\"]==transcript_exons[t][index_start][2]:\n",
    "#             index_start=index_start+1\n",
    "#         index_end=np.argmin(end_exon<row[\"start\"])\n",
    "#         if row[\"end\"]==transcript_exons[t][index_end][1]:\n",
    "#             index_end=index_end-1\n",
    "#         new_start=tuple([transcript_exons[t][index_start][0],row[\"end\"],transcript_exons[t][index_start][2],transcript_exons[t][index_start][3]])\n",
    "#         new_end=tuple([transcript_exons[t][index_end][0],transcript_exons[t][index_end][1],row[\"start\"],transcript_exons[t][index_end][3]])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_start]=new_start\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_end]=new_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyensembl.search.find_nearest_locus(start, end, loci)\n",
    "# Finds nearest locus (object with method distance_to_interval) to the interval defined by the given start and end positions. Returns the distance to that locus, along with the locus object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_protein=get_gene_list(novel_intron.loc[novel_intron[\"transcript_id\"]=='',\"genes\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(novel_intron.iloc[191][\"transcript_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PLGLB2'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_intron.loc[protein_intron[\"gene\"].isin(non_protein),\"gene\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome.transcript_ids_at_locus(contig=\"2\",position=88037624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No results found for query:\n\n            SELECT distinct transcript_id\n            FROM transcript\n            WHERE exon_id = ?\n        \nwith parameters: ['ENSE00000728678.1']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/common.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (<pyensembl.database.Database object at 0x7fa6e7979f50>, ('distinct', True), ('feature', 'transcript'), ('filter_column', 'exon_id'), ('filter_value', 'ENSE00000728678.1'), ('required', True), ('select_column_names', ('transcript_id',)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c8f0841f69ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscript_ids_of_exon_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ENSE00000728678.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/genome.py\u001b[0m in \u001b[0;36mtranscript_ids_of_exon_id\u001b[0;34m(self, exon_id)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranscript_ids_of_exon_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexon_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_transcript_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exon_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexon_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranscript_id_of_protein_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/genome.py\u001b[0m in \u001b[0;36m_query_transcript_ids\u001b[0;34m(self, property_name, value, feature)\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mdistinct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             required=True)\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/common.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/database.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, select_column_names, filter_column, filter_value, feature, distinct, required)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mquery_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilter_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         return self.run_sql_query(\n\u001b[0;32m--> 468\u001b[0;31m             sql, required=required, query_params=query_params)\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     def query_one(\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/database.py\u001b[0m in \u001b[0;36mrun_sql_query\u001b[0;34m(self, sql, required, query_params)\u001b[0m\n\u001b[1;32m    439\u001b[0m             raise ValueError(\n\u001b[1;32m    440\u001b[0m                 \"No results found for query:\\n%s\\nwith parameters: %s\" % (\n\u001b[0;32m--> 441\u001b[0;31m                     sql, query_params))\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No results found for query:\n\n            SELECT distinct transcript_id\n            FROM transcript\n            WHERE exon_id = ?\n        \nwith parameters: ['ENSE00000728678.1']"
     ]
    }
   ],
   "source": [
    "genome.transcript_ids_of_exon_id('ENSE00000728678.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENST00000331244.5', 'ENST00000368644.1', 'ENST00000481034.1']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome.transcript_ids_at_locus(contig=\"10\",position=131960844,end=131964771,strand=\"+\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_sns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
