{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyensembl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"~/projects/BIO/novel_junction.20230512.tsv\",sep=\"\\t\",index=False)\n",
    "data=pd.read_csv(\"~/projects/BIO/proteomics_MU_junction_all.20230529.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/rachelcw/miniconda3/envs/bio/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "all_intron=pd.read_csv(\"/home/ls/rachelcw/projects/BIO/annontation_code.20221225_all_introns.bed.gz\",sep=\"\\t\",header=None,compression=\"gzip\",usecols=[0,1,2,3,4,5,6,8],names=[\"chr\",\"start\",\"end\",\"gene\",\"gene_id\",\"strand\",\"transcript_id\",\"annotation\"])\n",
    "protein_intron=all_intron[all_intron[\"annotation\"]==\"protein_coding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to get the genes by individual.\n",
    "def get_gene_list(genelist):\n",
    "    data_gene_list=[]\n",
    "    for value in genelist:\n",
    "        value = value.split(',')\n",
    "        data_gene_list.extend(value)\n",
    "        \n",
    "    return list(set(data_gene_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************\n",
    "prepare data table- merge leafcutter ds results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutated VS unmutated SF3B1 - group 2 - M+U CLL\n",
    "\n",
    "# read in the data\n",
    "cluster = pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a2.20230512_cluster_significance.txt',sep=\" \")\n",
    "effect_size=pd.read_csv('~/projects/LEAFCUTTER/DS/DS.five_percent/analysis.20230512/fdr0.05/filtered.a2.20230512_effect_sizes.txt',sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered out junction mut(psi) > unmut(psi) --> delta psi < 0\n",
    "mutated=effect_size[effect_size[\"deltapsi\"]<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated[[\"chr\",\"start\",\"end\",\"cluster\"]]=mutated[\"intron\"].str.split(\":\",expand=True)\n",
    "mutated[\"start\"]=mutated[\"start\"].astype(int)\n",
    "mutated[\"end\"]=mutated[\"end\"].astype(int)\n",
    "cluster[[\"chr\",\"cluster\"]]=cluster[\"cluster\"].str.split(\":\",expand=True)\n",
    "mutated=mutated.merge(cluster,on=[\"chr\",\"cluster\"],how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=mutated.filter(items=[\"intron\",\"chr\",\"start\",\"end\",\"genes\",\"cluster\",\"p.adjust\"])\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtf=pd.read_csv(\"/private/resources/gencode19_noChrPrefix_mitoMT.gtf\",sep=\"\\t\", comment='#', header=None)\n",
    "# all_intron=pd.read_csv(\"/home/ls/rachelcw/projects/BIO/annontation_code.20221225_all_introns.bed.gz\",sep=\"\\t\",header=None,compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out intron that are not in the data\n",
    "data_gene_list=get_gene_list(data['genes'].unique())\n",
    "intron_in_data=protein_intron[protein_intron[\"gene\"].isin(data_gene_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = pyensembl.Genome(\n",
    "    reference_name='GRCh37',\n",
    "    annotation_name='my_genome_lab',\n",
    "    gtf_path_or_url='/home/ls/rachelcw/projects/protein_coding.gtf')\n",
    "genome.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"novel\"]=pd.NA\n",
    "data[\"transcript_id\"]=pd.NA\n",
    "for gene in data_gene_list:\n",
    "    # data_gene=data[data[\"genes\"].str.contains(gene)]\n",
    "    # intron_gene=intron_in_data[intron_in_data[\"gene\"].str.contains(gene)]\n",
    "    for index,row in data.iterrows():\n",
    "        if ((intron_in_data[\"start\"]==row[\"start\"])&(intron_in_data[\"end\"]==row[\"end\"])).any():\n",
    "            data.loc[index,\"novel\"]=\"known\"\n",
    "            trans_id=intron_in_data.loc[(intron_in_data[\"start\"]==row[\"start\"])&(intron_in_data[\"end\"]==row[\"end\"]),\"transcript_id\"]\n",
    "            data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "        elif (intron_in_data[\"start\"]==row[\"start\"]).any():\n",
    "            data.loc[index,\"novel\"]=\"start\"\n",
    "            trans_id=intron_in_data.loc[intron_in_data[\"start\"]==row[\"start\"],\"transcript_id\"]\n",
    "            data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "        elif (intron_in_data[\"end\"]==row[\"end\"]).any():\n",
    "            data.loc[index,\"novel\"]=\"end\"\n",
    "            trans_id=intron_in_data.loc[intron_in_data[\"end\"]==row[\"end\"],\"transcript_id\"]\n",
    "            data.loc[index,\"transcript_id\"]=','.join(trans_id)\n",
    "        else:\n",
    "            data.loc[index,\"novel\"]=\"novel\"\n",
    "            transcript_of_intron=genome.transcript_ids_at_locus(contig=row.chr.replace(\"chr\",\"\"),position=row.end)\n",
    "            if len(transcript_of_intron)>0:\n",
    "                data.loc[index,\"transcript_id\"]=','.join(transcript_of_intron)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['cluster','strand']]=data['cluster'].str.rsplit('_', expand=True, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows based on comma-separated values\n",
    "new_rows = []\n",
    "for index, row in data.iterrows():\n",
    "    values = row['genes'].split(',')\n",
    "    if len(values) > 1:\n",
    "        for i, value in enumerate(values):\n",
    "            new_row = row.copy()\n",
    "            new_row['genes'] = value\n",
    "            new_rows.append(new_row)\n",
    "    else:\n",
    "        new_rows.append(row)\n",
    "\n",
    "# Create updated DataFrame\n",
    "data = pd.DataFrame(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict={key: value for key, value in zip(protein_intron[\"gene\"].unique(),protein_intron[\"gene_id\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"gene_id\"]=data[\"genes\"].map(gene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop gene that arn't \"protein coding\" \n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"~/projects/BIO/proteomics_MU_junction_all.20230530.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out intron that are known\n",
    "novel_intron=data[data[\"novel\"]!=\"known\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list=get_gene_list(novel_intron[\"genes\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dictionary: key-transcript id, values- exons location of the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_exons=dict()\n",
    "for index, row in novel_intron.iterrows():\n",
    "    transcript=row[\"transcript_id\"].split(\",\")\n",
    "    for t in transcript:\n",
    "        if t not in transcript_exons:\n",
    "            exons=genome.exon_ids_of_transcript_id(t)\n",
    "            locus=[genome.locus_of_exon_id(exon).to_tuple() for exon in exons]\n",
    "            transcript_exons[t]=locus            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MappingProxyType\n",
    "# create the dictionary constant\n",
    "transcript_exons=MappingProxyType(transcript_exons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_exons_updated=transcript_exons.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"novel\"= start - we know the end of the exon \n",
    "so we want to find the next exon that is the closest to the end of the intron(start of the next exon) and replace the exon start with the intron end\n",
    "\n",
    "* \"novel\"= end - we know the start of the exon \n",
    "so we want to find the previous exon that is the closest to the start of the intron(end of the previous exon) and replace the exon end with the intron start\n",
    "\n",
    "* \"novel\" = novel intron -\n",
    "the intron is novel so we want to find the closest exons that the intron is between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_novel_gene_locus(transcript, start, end, novel):\n",
    "    locus=transcript_exons[transcript]\n",
    "    if novel==\"start\":\n",
    "        start_exon=np.array([l[1] for l in locus])\n",
    "        index_exon=np.argmax(start_exon>end)\n",
    "        if start==locus[index_exon][2]:\n",
    "            index_exon=index_exon+1\n",
    "        new_exon_locus=tuple([locus[index_exon][0],end,locus[index_exon][2],locus[index_exon][3]])\n",
    "        locus[index_exon]=new_exon_locus\n",
    "    elif novel==\"end\":\n",
    "        end_exon=np.array([l[2] for l in locus])\n",
    "        index_exon=np.argmin(end_exon<start)\n",
    "        if end==locus[index_exon][1]:\n",
    "            index_exon=index_exon-1\n",
    "        new_exon_locus=tuple([locus[index_exon][0],locus[index_exon][1],start,locus[index_exon][3]])\n",
    "        locus[index_exon]=new_exon_locus\n",
    "    elif novel==\"novel\":\n",
    "        start_exon=np.array([l[1] for l in locus])\n",
    "        end_exon=np.array([l[2] for l in locus])\n",
    "        index_start=np.argmax(start_exon>end)\n",
    "        if start==locus[index_start][2]:\n",
    "            index_start=index_start+1\n",
    "        index_end=np.argmin(end_exon<start)\n",
    "        if end==locus[index_end][1]:\n",
    "            index_end=index_end-1\n",
    "        new_start=tuple([locus[index_start][0],end,locus[index_start][2],locus[index_start][3]])\n",
    "        new_end=tuple([locus[index_end][0],locus[index_end][1],start,locus[index_end][3]])\n",
    "        locus[index_start]=new_start\n",
    "        locus[index_end]=new_end\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_gene_id=dict()\n",
    "for index, row in novel_intron.iterrows():\n",
    "    transcript=row[\"transcript_id\"].split(\",\")\n",
    "    for t in transcript:\n",
    "        transcript_gene_id[t]=row[\"gene_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file of the original exons #\n",
    "file_path=\"/home/ls/rachelcw/projects/BIO/cll_sf3b1_proteomics_original_draft.txt\"\n",
    "with open(file_path,'w') as file:\n",
    "    for t_id,locus in transcript_exons.items():\n",
    "        for loci in locus:\n",
    "            file.write(f'{loci[0]}\\t{loci[1]}\\t{loci[2]}\\t{loci[3]}\\t{t_id}\\t{transcript_gene_id[t_id]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path=\"/home/ls/rachelcw/projects/BIO/cll_sf3b1_proteomics_novel.txt\"\n",
    "# with open(file_path,'w') as file:\n",
    "#     for intron,t_id in intron_transcript.items():\n",
    "#         for t in t_id:\n",
    "#             for t_id,locus in t.items():\n",
    "#                 for loci in locus:\n",
    "#                     file.write(f'{loci[0]}\\t{loci[1]}\\t{loci[2]}\\t{loci[3]}\\t{t_id}\\t{transcript_gene_id[t_id]}\\t{intron}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"/home/ls/rachelcw/projects/BIO/cll_sf3b1_proteomics_novel.txt\"\n",
    "with open(file_path,'w') as file:\n",
    "    for index, row in novel_intron.iterrows():\n",
    "        transcript=row[\"transcript_id\"].split(\",\")\n",
    "        for t in transcript:\n",
    "            locus=get_novel_gene_locus(t,row[\"start\"],row[\"end\"],row[\"novel\"])\n",
    "            for loci in locus:\n",
    "                file.write(f'{loci[0]}\\t{loci[1]}\\t{loci[2]}\\t{loci[3]}\\t{t}\\t{transcript_gene_id[t]}\\t{row[\"intron\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option to frame shift- need to change the modulo to the len of the gene until the new locus # #\n",
    "# start_novel_intron=novel_intron[novel_intron[\"novel\"]==\"start\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in start_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     t_frame=[]\n",
    "#     for t in transcript:\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         print(row[\"end\"])\n",
    "#         print(start_exon)\n",
    "#         index_exon=np.abs(start_exon-row[\"end\"]).argmin()\n",
    "#         print(index_exon)\n",
    "#         print(\"old\",transcript_exons[t][index_exon])\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],row[\"end\"],transcript_exons[t][index_exon][2],transcript_exons[t][index_exon][3]])\n",
    "#         transcript_exons_updated[t][index_exon]=new_exon_locus\n",
    "#         if (transcript_exons[t][index_exon][2]-transcript_exons[t][index_exon][1]-1)%3!=0:\n",
    "#             print(\"new\",new_exon_locus)\n",
    "#             t_frame.append(t)\n",
    "#     start_novel_intron.loc[index,\"frameshift\"]=','.join(t_frame)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my tryint to create a dictionary of {intron(junction):{t_is:[exons locus]}} ##\n",
    "\n",
    "# intron_transcript=dict()\n",
    "# for index, row in novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     intron_transcript[row[\"intron\"]] = [{t: transcript_exons[t]} for t in transcript]\n",
    "\n",
    "# start_novel_intron=novel_intron[novel_intron[\"novel\"]==\"start\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in start_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         index_exon=np.argmax(start_exon>row[\"end\"])\n",
    "#         if row[\"start\"]==transcript_exons[t][index_exon][2]:\n",
    "#             index_exon=index_exon+1\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],row[\"end\"],transcript_exons[t][index_exon][2],transcript_exons[t][index_exon][3]])\n",
    "#         # print(intron_transcript[row[\"intron\"]][i][t][index_exon])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_exon]=new_exon_locus\n",
    "#         # print(intron_transcript[row[\"intron\"]][i][t][index_exon])\n",
    "#         # print(t)\n",
    "#         # print(row[\"end\"])\n",
    "#         # print(start_exon)\n",
    "#         # print(index_exon)\n",
    "#         # print(\"old\",transcript_exons[t][index_exon])\n",
    "#         # print(transcript_exons[t])\n",
    "#         # print(\"new\",new_exon_locus)\n",
    "           \n",
    "# end_novel_intron=novel_intron[novel_intron[\"novel\"]==\"end\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in end_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     # t_frame=[]\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         end_exon=np.array([l[2] for l in transcript_exons[t]])\n",
    "#         index_exon=np.argmin(end_exon<row[\"start\"])\n",
    "#         if row[\"end\"]==transcript_exons[t][index_exon][1]:\n",
    "#             index_exon=index_exon-1\n",
    "#         new_exon_locus=tuple([transcript_exons[t][index_exon][0],transcript_exons[t][index_exon][1],row[\"start\"],transcript_exons[t][index_exon][3]])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_exon]=new_exon_locus\n",
    "#         # print(end_exon<row[\"start\"])\n",
    "#         # print(t)\n",
    "#         # print(row[\"start\"])\n",
    "#         # print(end_exon)\n",
    "#         # print(index_exon)\n",
    "#         # print(\"old\",transcript_exons[t][index_exon])\n",
    "#         # print(transcript_exons[t])\n",
    "#         # print(\"new\",new_exon_locus)\n",
    "\n",
    "# novel_novel_intron=novel_intron[novel_intron[\"novel\"]==\"novel\"]\n",
    "# # start_novel_intron[\"frameshift\"]=0\n",
    "# for index, row in novel_novel_intron.iterrows():\n",
    "#     transcript=row[\"transcript_id\"].split(\",\")\n",
    "#     # t_frame=[]\n",
    "#     for i,t in enumerate(transcript):\n",
    "#         start_exon=np.array([l[1] for l in transcript_exons[t]])\n",
    "#         end_exon=np.array([l[2] for l in transcript_exons[t]])\n",
    "#         index_start=np.argmax(start_exon>row[\"end\"])\n",
    "#         if row[\"start\"]==transcript_exons[t][index_start][2]:\n",
    "#             index_start=index_start+1\n",
    "#         index_end=np.argmin(end_exon<row[\"start\"])\n",
    "#         if row[\"end\"]==transcript_exons[t][index_end][1]:\n",
    "#             index_end=index_end-1\n",
    "#         new_start=tuple([transcript_exons[t][index_start][0],row[\"end\"],transcript_exons[t][index_start][2],transcript_exons[t][index_start][3]])\n",
    "#         new_end=tuple([transcript_exons[t][index_end][0],transcript_exons[t][index_end][1],row[\"start\"],transcript_exons[t][index_end][3]])\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_start]=new_start\n",
    "#         intron_transcript[row[\"intron\"]][i][t][index_end]=new_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyensembl.search.find_nearest_locus(start, end, loci)\n",
    "# Finds nearest locus (object with method distance_to_interval) to the interval defined by the given start and end positions. Returns the distance to that locus, along with the locus object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_protein=get_gene_list(novel_intron.loc[novel_intron[\"transcript_id\"]=='',\"genes\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(novel_intron.iloc[191][\"transcript_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PLGLB2'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_intron.loc[protein_intron[\"gene\"].isin(non_protein),\"gene\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome.transcript_ids_at_locus(contig=\"2\",position=88037624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No results found for query:\n\n            SELECT distinct transcript_id\n            FROM transcript\n            WHERE exon_id = ?\n        \nwith parameters: ['ENSE00000728678.1']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/common.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (<pyensembl.database.Database object at 0x7fa6e7979f50>, ('distinct', True), ('feature', 'transcript'), ('filter_column', 'exon_id'), ('filter_value', 'ENSE00000728678.1'), ('required', True), ('select_column_names', ('transcript_id',)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c8f0841f69ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscript_ids_of_exon_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ENSE00000728678.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/genome.py\u001b[0m in \u001b[0;36mtranscript_ids_of_exon_id\u001b[0;34m(self, exon_id)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranscript_ids_of_exon_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexon_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_transcript_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exon_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexon_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranscript_id_of_protein_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/genome.py\u001b[0m in \u001b[0;36m_query_transcript_ids\u001b[0;34m(self, property_name, value, feature)\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mdistinct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             required=True)\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/common.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/database.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, select_column_names, filter_column, filter_value, feature, distinct, required)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mquery_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilter_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         return self.run_sql_query(\n\u001b[0;32m--> 468\u001b[0;31m             sql, required=required, query_params=query_params)\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     def query_one(\n",
      "\u001b[0;32m~/miniconda3/envs/bio/lib/python3.7/site-packages/pyensembl/database.py\u001b[0m in \u001b[0;36mrun_sql_query\u001b[0;34m(self, sql, required, query_params)\u001b[0m\n\u001b[1;32m    439\u001b[0m             raise ValueError(\n\u001b[1;32m    440\u001b[0m                 \"No results found for query:\\n%s\\nwith parameters: %s\" % (\n\u001b[0;32m--> 441\u001b[0;31m                     sql, query_params))\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No results found for query:\n\n            SELECT distinct transcript_id\n            FROM transcript\n            WHERE exon_id = ?\n        \nwith parameters: ['ENSE00000728678.1']"
     ]
    }
   ],
   "source": [
    "genome.transcript_ids_of_exon_id('ENSE00000728678.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENST00000331244.5', 'ENST00000368644.1', 'ENST00000481034.1']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome.transcript_ids_at_locus(contig=\"10\",position=131960844,end=131964771,strand=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENSE00002174390.1',\n",
       " 'ENSE00000728668.1',\n",
       " 'ENSE00003477570.1',\n",
       " 'ENSE00000728676.1',\n",
       " 'ENSE00000728678.1',\n",
       " 'ENSE00000728681.1',\n",
       " 'ENSE00000728683.1',\n",
       " 'ENSE00000728687.1',\n",
       " 'ENSE00000728691.1',\n",
       " 'ENSE00000577957.1',\n",
       " 'ENSE00001217321.1',\n",
       " 'ENSE00001217252.2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome.exon_ids_of_transcript_id(\"ENST00000368644.1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_sns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
